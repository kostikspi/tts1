{
  "name": "fast_test",
  "n_gpu": 1,
  "preprocessing": {
    "sr": 16000,
    "spectrogram": {
      "type": "MelSpectrogram",
      "args": {
      }
    },
    "log_spec": true
  },
  "augmentations": {
    "wave": [],
    "spectrogram": []
  },
  "arch": {
    "type": "FastSpeech",
    "args": {
      "model_config": {
        "num_mels": 128,
        "vocab_size": 300,
        "max_seq_len": 3000,
        "encoder_dim": 256,
        "encoder_n_layer": 4,
        "encoder_head": 2,
        "encoder_conv1d_filter_size": 1024,
        "decoder_dim": 256,
        "decoder_n_layer": 4,
        "decoder_head": 2,
        "decoder_conv1d_filter_size": 1024,
        "fft_conv1d_kernel": [
          9,
          1
        ],
        "fft_conv1d_padding": [
          4,
          0
        ],
        "duration_predictor_filter_size": 256,
        "duration_predictor_kernel_size": 3,
        "dropout": 0.1,
        "pitch_predictor_filter_size": 256,
        "pitch_predictor_kernel_size": 3,
        "PAD": 0,
        "UNK": 1,
        "BOS": 2,
        "EOS": 3,
        "PAD_WORD": "<blank>",
        "UNK_WORD": "<unk>",
        "BOS_WORD": "<s>",
        "EOS_WORD": "</s>"
      }
    }
  },
  "data": {
    "train": {
      "batch_size": 2,
      "num_workers": 0,
      "datasets": [
        {
          "type": "LJspeechDataset",
          "args": {
            "part": "train",
            "max_audio_length": 20.0,
            "max_text_length": 200,
            "limit": 10
          }
        }
      ]
    },
    "test": {
      "batch_size": 1,
      "num_workers": 0,
      "datasets": [
        {
          "type": "LJspeechDataset",
          "args": {
            "part": "test",
            "max_audio_length": 20.0,
            "max_text_length": 200,
            "limit": 10
          }
        }
      ]
    }
  },
  "metrics": [
  ],
  "optimizer": {
    "type": "SGD",
    "args": {
      "lr": 1e-2
    }
  },
  "loss": {
    "type": "FastSpeechLoss",
    "args": {}
  },
  "lr_scheduler": {
    "type": "OneCycleLR",
    "args": {
      "steps_per_epoch": 100,
      "epochs": 50,
      "anneal_strategy": "cos",
      "max_lr": 1e-2,
      "pct_start": 0.2
    }
  },
  "trainer": {
    "epochs": 50,
    "save_dir": "saved/",
    "save_period": 5,
    "verbosity": 2,
    "monitor": "min val_loss",
    "early_stop": 100,
    "visualize": "wandb",
    "wandb_project": "tts_project",
    "len_epoch": 100,
    "grad_norm_clip": 10
  }
}
